2021-02-25 22:50:40,388 ----------------------------------------------------------------------------------------------------
2021-02-25 22:50:40,395 Model: "FlairTokenizer(
  (character_embeddings): Embedding(89, 4096)
  (embeddings): Embedding(89, 4096)
  (lstm): LSTM(4096, 256, bidirectional=True)
  (hidden2tag): Linear(in_features=512, out_features=5, bias=True)
  (loss_function): NLLLoss()
)"
2021-02-25 22:50:40,398 ----------------------------------------------------------------------------------------------------
2021-02-25 22:50:40,407 Corpus: "Corpus: 125 train + 20 dev + 21 test sentences"
2021-02-25 22:50:40,443 ----------------------------------------------------------------------------------------------------
2021-02-25 22:50:40,511 Parameters:
2021-02-25 22:50:40,523  - learning_rate: "0.1"
2021-02-25 22:50:40,528  - mini_batch_size: "1"
2021-02-25 22:50:40,530  - patience: "3"
2021-02-25 22:50:40,532  - anneal_factor: "0.5"
2021-02-25 22:50:40,537  - max_epochs: "5"
2021-02-25 22:50:40,541  - shuffle: "True"
2021-02-25 22:50:40,543  - train_with_dev: "False"
2021-02-25 22:50:40,545  - batch_growth_annealing: "False"
2021-02-25 22:50:40,550 ----------------------------------------------------------------------------------------------------
2021-02-25 22:50:40,556 Model training base path: "resources/taggers/example-tokenizer"
2021-02-25 22:50:40,561 ----------------------------------------------------------------------------------------------------
2021-02-25 22:50:40,564 Device: cpu
2021-02-25 22:50:40,566 ----------------------------------------------------------------------------------------------------
2021-02-25 22:50:40,570 Embeddings storage mode: cpu
2021-02-25 22:50:40,576 ----------------------------------------------------------------------------------------------------
2021-02-25 22:50:43,523 epoch 1 - iter 12/125 - loss 1.08037817 - samples/sec: 4.10 - lr: 0.100000
2021-02-25 22:50:46,332 epoch 1 - iter 24/125 - loss 0.89986524 - samples/sec: 4.27 - lr: 0.100000
2021-02-25 22:50:49,687 epoch 1 - iter 36/125 - loss 0.78507479 - samples/sec: 3.58 - lr: 0.100000
2021-02-25 22:50:52,448 epoch 1 - iter 48/125 - loss 0.70438411 - samples/sec: 4.35 - lr: 0.100000
2021-02-25 22:50:55,438 epoch 1 - iter 60/125 - loss 0.66236618 - samples/sec: 4.01 - lr: 0.100000
2021-02-25 22:50:58,357 epoch 1 - iter 72/125 - loss 0.60302559 - samples/sec: 4.11 - lr: 0.100000
2021-02-25 22:51:00,975 epoch 1 - iter 84/125 - loss 0.56399851 - samples/sec: 4.59 - lr: 0.100000
2021-02-25 22:51:04,413 epoch 1 - iter 96/125 - loss 0.52516502 - samples/sec: 3.49 - lr: 0.100000
2021-02-25 22:51:07,131 epoch 1 - iter 108/125 - loss 0.49419962 - samples/sec: 4.42 - lr: 0.100000
2021-02-25 22:51:09,917 epoch 1 - iter 120/125 - loss 0.48620653 - samples/sec: 4.31 - lr: 0.100000
2021-02-25 22:51:12,031 ----------------------------------------------------------------------------------------------------
2021-02-25 22:51:12,032 EPOCH 1 done: loss 0.4770 - lr 0.1000000
2021-02-25 22:51:13,220 DEV : loss 4.430708885192871 - score 0.7748
2021-02-25 22:51:13,221 BAD EPOCHS (no improvement): 0
2021-02-25 22:51:13,328 ----------------------------------------------------------------------------------------------------
2021-02-25 22:51:16,462 epoch 2 - iter 12/125 - loss 0.15733153 - samples/sec: 3.83 - lr: 0.100000
2021-02-25 22:51:20,149 epoch 2 - iter 24/125 - loss 0.19660566 - samples/sec: 3.26 - lr: 0.100000
2021-02-25 22:51:24,284 epoch 2 - iter 36/125 - loss 0.18979445 - samples/sec: 2.90 - lr: 0.100000
2021-02-25 22:51:27,762 epoch 2 - iter 48/125 - loss 0.19312738 - samples/sec: 3.45 - lr: 0.100000
2021-02-25 22:51:32,210 epoch 2 - iter 60/125 - loss 0.19381921 - samples/sec: 2.70 - lr: 0.100000
2021-02-25 22:51:35,791 epoch 2 - iter 72/125 - loss 0.18339691 - samples/sec: 3.35 - lr: 0.100000
2021-02-25 22:51:38,913 epoch 2 - iter 84/125 - loss 0.18382838 - samples/sec: 3.85 - lr: 0.100000
2021-02-25 22:51:40,803 epoch 2 - iter 96/125 - loss 0.20409784 - samples/sec: 6.35 - lr: 0.100000
2021-02-25 22:51:44,465 epoch 2 - iter 108/125 - loss 0.19696462 - samples/sec: 3.28 - lr: 0.100000
2021-02-25 22:51:48,810 epoch 2 - iter 120/125 - loss 0.19287248 - samples/sec: 2.76 - lr: 0.100000
2021-02-25 22:51:50,561 ----------------------------------------------------------------------------------------------------
2021-02-25 22:51:50,562 EPOCH 2 done: loss 0.1891 - lr 0.1000000
2021-02-25 22:51:51,263 DEV : loss 3.3841559886932373 - score 0.8611
2021-02-25 22:51:51,264 BAD EPOCHS (no improvement): 0
2021-02-25 22:51:51,343 ----------------------------------------------------------------------------------------------------
2021-02-25 22:51:53,778 epoch 3 - iter 12/125 - loss 0.15743598 - samples/sec: 4.93 - lr: 0.100000
2021-02-25 22:51:56,328 epoch 3 - iter 24/125 - loss 0.16363459 - samples/sec: 4.71 - lr: 0.100000
2021-02-25 22:51:58,618 epoch 3 - iter 36/125 - loss 0.17551289 - samples/sec: 5.24 - lr: 0.100000
2021-02-25 22:52:01,037 epoch 3 - iter 48/125 - loss 0.15324032 - samples/sec: 4.96 - lr: 0.100000
2021-02-25 22:52:05,016 epoch 3 - iter 60/125 - loss 0.15718249 - samples/sec: 3.02 - lr: 0.100000
2021-02-25 22:52:08,888 epoch 3 - iter 72/125 - loss 0.14982885 - samples/sec: 3.10 - lr: 0.100000
2021-02-25 22:52:11,402 epoch 3 - iter 84/125 - loss 0.14437647 - samples/sec: 4.78 - lr: 0.100000
2021-02-25 22:52:13,592 epoch 3 - iter 96/125 - loss 0.14211327 - samples/sec: 5.48 - lr: 0.100000
2021-02-25 22:52:16,001 epoch 3 - iter 108/125 - loss 0.13442263 - samples/sec: 4.98 - lr: 0.100000
2021-02-25 22:52:18,797 epoch 3 - iter 120/125 - loss 0.12982604 - samples/sec: 4.29 - lr: 0.100000
2021-02-25 22:52:20,084 ----------------------------------------------------------------------------------------------------
2021-02-25 22:52:20,085 EPOCH 3 done: loss 0.1272 - lr 0.1000000
2021-02-25 22:52:20,756 DEV : loss 3.041337251663208 - score 0.8483
2021-02-25 22:52:20,757 BAD EPOCHS (no improvement): 1
2021-02-25 22:52:20,759 ----------------------------------------------------------------------------------------------------
2021-02-25 22:52:23,635 epoch 4 - iter 12/125 - loss 0.10051427 - samples/sec: 4.18 - lr: 0.100000
2021-02-25 22:52:26,291 epoch 4 - iter 24/125 - loss 0.09331031 - samples/sec: 4.52 - lr: 0.100000
2021-02-25 22:52:28,387 epoch 4 - iter 36/125 - loss 0.08894846 - samples/sec: 5.73 - lr: 0.100000
2021-02-25 22:52:30,915 epoch 4 - iter 48/125 - loss 0.09116321 - samples/sec: 4.75 - lr: 0.100000
2021-02-25 22:52:34,127 epoch 4 - iter 60/125 - loss 0.10075876 - samples/sec: 3.74 - lr: 0.100000
2021-02-25 22:52:36,553 epoch 4 - iter 72/125 - loss 0.10120443 - samples/sec: 4.95 - lr: 0.100000
2021-02-25 22:52:39,062 epoch 4 - iter 84/125 - loss 0.10708971 - samples/sec: 4.78 - lr: 0.100000
2021-02-25 22:52:41,626 epoch 4 - iter 96/125 - loss 0.10922579 - samples/sec: 4.68 - lr: 0.100000
2021-02-25 22:52:44,054 epoch 4 - iter 108/125 - loss 0.10553208 - samples/sec: 4.94 - lr: 0.100000
2021-02-25 22:52:46,622 epoch 4 - iter 120/125 - loss 0.10129785 - samples/sec: 4.68 - lr: 0.100000
2021-02-25 22:52:47,827 ----------------------------------------------------------------------------------------------------
2021-02-25 22:52:47,827 EPOCH 4 done: loss 0.0993 - lr 0.1000000
2021-02-25 22:52:48,484 DEV : loss 2.7519869804382324 - score 0.873
2021-02-25 22:52:48,485 BAD EPOCHS (no improvement): 0
2021-02-25 22:52:48,551 ----------------------------------------------------------------------------------------------------
2021-02-25 22:52:54,377 epoch 5 - iter 12/125 - loss 0.06846732 - samples/sec: 2.06 - lr: 0.100000
2021-02-25 22:52:57,089 epoch 5 - iter 24/125 - loss 0.09929434 - samples/sec: 4.43 - lr: 0.100000
2021-02-25 22:52:59,600 epoch 5 - iter 36/125 - loss 0.09762416 - samples/sec: 4.78 - lr: 0.100000
2021-02-25 22:53:01,857 epoch 5 - iter 48/125 - loss 0.08912697 - samples/sec: 5.32 - lr: 0.100000
2021-02-25 22:53:03,936 epoch 5 - iter 60/125 - loss 0.08560802 - samples/sec: 5.78 - lr: 0.100000
2021-02-25 22:53:07,484 epoch 5 - iter 72/125 - loss 0.08358920 - samples/sec: 3.38 - lr: 0.100000
2021-02-25 22:53:11,662 epoch 5 - iter 84/125 - loss 0.08227536 - samples/sec: 2.87 - lr: 0.100000
2021-02-25 22:53:14,904 epoch 5 - iter 96/125 - loss 0.08156747 - samples/sec: 3.70 - lr: 0.100000
2021-02-25 22:53:17,413 epoch 5 - iter 108/125 - loss 0.07840696 - samples/sec: 4.79 - lr: 0.100000
2021-02-25 22:53:19,731 epoch 5 - iter 120/125 - loss 0.08147690 - samples/sec: 5.18 - lr: 0.100000
2021-02-25 22:53:21,108 ----------------------------------------------------------------------------------------------------
2021-02-25 22:53:21,109 EPOCH 5 done: loss 0.0803 - lr 0.1000000
2021-02-25 22:53:21,764 DEV : loss 2.8066651821136475 - score 0.8905
2021-02-25 22:53:21,765 BAD EPOCHS (no improvement): 0
2021-02-25 22:53:21,930 ----------------------------------------------------------------------------------------------------
2021-02-25 22:53:21,931 Testing using best model ...
2021-02-25 22:53:21,933 loading file resources/taggers/example-tokenizer/best-model.pt
2021-02-25 22:53:22,749 	0.7155895691609978
2021-02-25 22:53:22,750 
Results:
- F1-score : 0.7245898974143148
- Precision-score : 0.7503668133920235
- Recall-score : 0.7155895691609978
2021-02-25 22:53:22,751 ----------------------------------------------------------------------------------------------------
